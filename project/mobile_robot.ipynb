{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import pinocchio as pin\n",
    "from pinocchio.visualize import MeshcatVisualizer\n",
    "from meshcat.transformations import translation_matrix, rotation_matrix\n",
    "from meshcat.geometry import Box, MeshPhongMaterial, Cylinder\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify a path the the urdf files and meshes\n",
    "urdf_model_path = \"diffdrive.urdf\"\n",
    "mesh_dir = \"\"\n",
    "\n",
    "\"\"\" \n",
    "Initalize parameters for the robot\n",
    "\"\"\"\n",
    "\n",
    "RADIUS = 0.25  # Radius of the robot (from the URDF)\n",
    "START = [-4.5, 0, np.pi/2]  # Starting position of the robot\n",
    "# START = [-4.25, -2, 0] \n",
    "GOAL = [-2, -2, 0]  # Goal position of the robot\n",
    "SEED = 42 # Seed for random number generation\n",
    "NUMBER_OF_NODES = 1000 # Number of nodes in the graph\n",
    "NUMBER_OF_NEIGHBORS = 10 # Number of neighbors to consider for each node\n",
    "\n",
    "# load the robot using pinocchio\n",
    "robot = pin.RobotWrapper.BuildFromURDF(urdf_model_path, mesh_dir)\n",
    "\n",
    "# vizualize the robot using meshcat\n",
    "viz = MeshcatVisualizer(robot.model, robot.collision_model, robot.visual_model)\n",
    "viz.initViewer(loadModel=True)\n",
    "\n",
    "def show_robot(x,y,theta):\n",
    "    quat = pin.Quaternion(pin.utils.rotate('z', theta)).coeffs()\n",
    "    pos = np.array([x,y,0.1])\n",
    "\n",
    "    viz.display(np.append(pos,quat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a floor\n",
    "# Add floor material\n",
    "material_floor = MeshPhongMaterial()\n",
    "material_floor.color = int(200) * 256**2 + int(200) * 256 + int(200)\n",
    "# Add a floor\n",
    "viz.viewer[\"/Floor\"].set_object(\n",
    "    Box([10, 10, 0.01]),\n",
    "    material_floor\n",
    ")\n",
    "viz.viewer[\"/Floor\"].set_transform(\n",
    "    translation_matrix([0, 0, -0.005])\n",
    ")\n",
    "\n",
    "# Add obstacle material\n",
    "material_obstacle = MeshPhongMaterial()\n",
    "material_obstacle.color = int(100) * 256**2 + int(100) * 256 + int(100)\n",
    "\n",
    "# Randomly generate 10 obstacle positions within a defined range\n",
    "np.random.seed(SEED)\n",
    "obstacle_positions = [\n",
    "    np.array([np.random.uniform(-4.8, 4.8), np.random.uniform(-4.8, 4.8), 0.5])\n",
    "    for _ in range(10)\n",
    "] # 10 obstacles, defined as x, y, z positions\n",
    "\n",
    "# add cylinders for each obstacle\n",
    "for i, pos in enumerate(obstacle_positions):\n",
    "    viz.viewer[f\"/Obstacle_{i}\"].set_object(\n",
    "        Cylinder(1, 0.2), material_obstacle\n",
    "    )\n",
    "    T_world_obs = translation_matrix(pos)\n",
    "    T_world_obs[:3, :3] = pin.utils.rotate('x', np.pi / 2)\n",
    "    viz.viewer[f\"/Obstacle_{i}\"].set_transform(\n",
    "        T_world_obs\n",
    "    )\n",
    "\n",
    "# Add walls between obstacles, for every two obstacles\n",
    "for i, pos in enumerate(obstacle_positions[::2]):\n",
    "    # Connect a wall (box) between the two obstacles\n",
    "    wall_length = np.linalg.norm(obstacle_positions[2*i][:2] - obstacle_positions[2*i+1][:2])\n",
    "    wall_width = 0.4\n",
    "    wall_height = 1.0\n",
    "    wall_material = MeshPhongMaterial()\n",
    "    wall_material.color = int(100) * 256**2 + int(100) * 256 + int(100)\n",
    "\n",
    "    wall_position = (obstacle_positions[2*i][:2] + obstacle_positions[2*i+1][:2]) / 2\n",
    "\n",
    "    viz.viewer[f\"/Wall_Obstacle_{i}\"].set_object(\n",
    "        Box([wall_length, wall_width, wall_height]), wall_material\n",
    "    )\n",
    "    # Set the wall rotation to align with the line between the two obstacles\n",
    "    angle = np.arctan2(\n",
    "        obstacle_positions[2*i+1][1] - obstacle_positions[2*i][1],\n",
    "        obstacle_positions[2*i+1][0] - obstacle_positions[2*i][0]\n",
    "    )\n",
    "    viz.viewer[f\"/Wall_Obstacle_{i}\"].set_transform(\n",
    "        translation_matrix([wall_position[0], wall_position[1], wall_height / 2]) @\n",
    "        rotation_matrix(angle, [0, 0, 1])\n",
    "    )\n",
    "\n",
    "# Add walls around the floor\n",
    "wall_thickness = 0.1\n",
    "wall_height = 1.0\n",
    "\n",
    "# Left wall\n",
    "viz.viewer[\"/Wall_Left\"].set_object(Box([wall_thickness, 10, wall_height]))\n",
    "viz.viewer[\"/Wall_Left\"].set_transform(\n",
    "    translation_matrix([-5 - wall_thickness / 2, 0, wall_height / 2])\n",
    ")\n",
    "\n",
    "# Right wall\n",
    "viz.viewer[\"/Wall_Right\"].set_object(Box([wall_thickness, 10, wall_height]))\n",
    "viz.viewer[\"/Wall_Right\"].set_transform(\n",
    "    translation_matrix([5 + wall_thickness / 2, 0, wall_height / 2])\n",
    ")\n",
    "\n",
    "# Front wall\n",
    "viz.viewer[\"/Wall_Front\"].set_object(Box([10, wall_thickness, wall_height]))\n",
    "viz.viewer[\"/Wall_Front\"].set_transform(\n",
    "    translation_matrix([0, 5 + wall_thickness / 2, wall_height / 2])\n",
    ")\n",
    "\n",
    "# Back wall\n",
    "viz.viewer[\"/Wall_Back\"].set_object(Box([10, wall_thickness, wall_height]))\n",
    "viz.viewer[\"/Wall_Back\"].set_transform(\n",
    "    translation_matrix([0, -5 - wall_thickness / 2, wall_height / 2])\n",
    ")\n",
    "\n",
    "# can you add a tower in each corner of the walls?\n",
    "tower_height = 1.5\n",
    "tower_radius = 0.3\n",
    "tower_material = MeshPhongMaterial()\n",
    "tower_material.color = int(100) * 256**2 + int(100) * 256 + int(100)\n",
    "\n",
    "tower_positions = [\n",
    "    np.array([-5 - wall_thickness / 2, 5 + wall_thickness / 2, tower_height / 2]),\n",
    "    # first element is the x position, second is the y position, third is the z position\n",
    "    np.array([5 + wall_thickness / 2, 5 + wall_thickness / 2, tower_height / 2]),\n",
    "    np.array([-5 - wall_thickness / 2, -5 - wall_thickness / 2, tower_height / 2]),\n",
    "    np.array([5 + wall_thickness / 2, -5 - wall_thickness / 2, tower_height / 2])\n",
    "]\n",
    "\n",
    "for i, pos in enumerate(tower_positions):\n",
    "    viz.viewer[f\"/Tower_{i}\"].set_object(\n",
    "        Cylinder(tower_height, tower_radius), tower_material\n",
    "    )\n",
    "    T_world_tower = translation_matrix(pos)\n",
    "    T_world_tower[:3, :3] = pin.utils.rotate('x', np.pi / 2)\n",
    "    viz.viewer[f\"/Tower_{i}\"].set_transform(\n",
    "        T_world_tower\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, theta = START\n",
    "# grid is:\n",
    "# x [-5, 5]\n",
    "# y [-5, 5]\n",
    "# theta [0, 2*pi]\n",
    "show_robot(x,y,theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define robot dynamics\n",
    "def discrete_dynamics(state, control_input, dt, model_mismatch=False):\n",
    "    \"\"\"\n",
    "    Update the robot's state based on its dynamics.\n",
    "\n",
    "    Parameters:\n",
    "    - state: Current state [x, y, theta]\n",
    "    - control_input: Control input [linear_velocity, angular_velocity]\n",
    "    - dt: Time step\n",
    "\n",
    "    Returns:\n",
    "    - Updated state [x, y, theta]\n",
    "    \"\"\"\n",
    "    x, y, theta = state\n",
    "    linear_velocity, angular_velocity = control_input\n",
    "    if model_mismatch:\n",
    "        # Introduce model mismatch by adding noise to the control input\n",
    "        linear_velocity += np.random.normal(0, 1.0)\n",
    "        angular_velocity += np.random.normal(0, 1.0)\n",
    "\n",
    "    # Update state using differential drive kinematics\n",
    "    x += linear_velocity * np.cos(theta) * dt\n",
    "    y += linear_velocity * np.sin(theta) * dt\n",
    "    theta += angular_velocity * dt\n",
    "\n",
    "    # Normalize theta to keep it within [-pi, pi]\n",
    "    theta = np.arctan2(np.sin(theta), np.cos(theta))\n",
    "\n",
    "    return np.array([x, y, theta])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation(controller, mismatch=False):\n",
    "    # Simulation parameters\n",
    "    dt = 0.01  # Time step (s)\n",
    "    simulation_time = 30  # Total simulation time (s)\n",
    "    sensor_noise_stddev = 0.03  # Standard deviation of sensor noise (m)\n",
    "\n",
    "    # Initial robot position and orientation\n",
    "    x, y, theta = START  # Initial position (x, y) and orientation (theta)\n",
    "\n",
    "    # Simulation loop\n",
    "    for t in np.arange(0, simulation_time, dt):\n",
    "\n",
    "        z = np.array([x,y]) + np.random.normal(0, sensor_noise_stddev, 2)  # Simulated sensor measurement with noise\n",
    "\n",
    "        # calculate control inputs\n",
    "        u,w = controller(x,y,theta,z)\n",
    "        # u = linear_velocity\n",
    "        # w = angular_velocity\n",
    "\n",
    "        # Update robot position and orientation using differential drive kinematics\n",
    "        x, y, theta = discrete_dynamics([x, y, theta], [u,w], dt, model_mismatch=mismatch)\n",
    "\n",
    "        # Normalize theta to keep it within [-pi, pi]\n",
    "        theta = np.arctan2(np.sin(theta), np.cos(theta))\n",
    "\n",
    "        # Display the robot in the visualization\n",
    "        show_robot(x, y, theta)\n",
    "        # Calculate and visualize distances to towers\n",
    "        \n",
    "        if np.linalg.norm([x - GOAL[0], y - GOAL[1]]) <= 0.2:\n",
    "            print(\"Goal reached!\")\n",
    "            break\n",
    "\n",
    "        # Pause to simulate real-time visualization\n",
    "        time.sleep(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motion Planning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collision Check Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_obstacles():\n",
    "    \"\"\" \n",
    "    Obstacles are defined as a list of tuples, where each tuple contains:\n",
    "    - start point (x, y)\n",
    "    - end point (x, y)\n",
    "    - radius (for cylindrical obstacles)\n",
    "    The obstacles are defined as follows:\n",
    "    1. Individual cylindrical obstacles (radius = 0.2)\n",
    "    2. Walls between obstacle pairs (width = 0.4 -> radius = 0.2)\n",
    "    3. Boundary walls (thickness = 0.1 -> radius = 0.05)\n",
    "    4. Corner towers (radius = 0.3)\n",
    "    \"\"\"\n",
    "    obstacles = []\n",
    "\n",
    "    # 1. Individual cylindrical obstacles (radius = 0.2)\n",
    "    for pos in obstacle_positions:\n",
    "        x, y = pos[0], pos[1]\n",
    "        obstacles.append(((x, y), (x, y), 0.2))  # Zero-length capsule (circle)\n",
    "\n",
    "    # 2. Walls between obstacle pairs (width = 0.4 -> radius = 0.2)\n",
    "    for i in range(len(obstacle_positions) // 2):\n",
    "        start_obs = obstacle_positions[2*i]\n",
    "        end_obs = obstacle_positions[(2*i)+1]\n",
    "        start = (start_obs[0], start_obs[1])\n",
    "        end = (end_obs[0], end_obs[1])\n",
    "        obstacles.append((start, end, 0.2))\n",
    "\n",
    "    # 3. Boundary walls (thickness = 0.1 -> radius = 0.05)\n",
    "    obstacles.extend([\n",
    "        # Left wall (x=-5.05)\n",
    "        ((-5.05, -5), (-5.05, 5), 0.05),\n",
    "        # Right wall (x=5.05)\n",
    "        ((5.05, -5), (5.05, 5), 0.05),\n",
    "        # Front wall (y=5.05)\n",
    "        ((-5, 5.05), (5, 5.05), 0.05),\n",
    "        # Back wall (y=-5.05)\n",
    "        ((-5, -5.05), (5, -5.05), 0.05)\n",
    "    ])\n",
    "\n",
    "    # 4. Corner towers (radius = 0.3)\n",
    "    for pos in tower_positions:\n",
    "        x, y = pos[0], pos[1]\n",
    "        obstacles.append(((x, y), (x, y), 0.3))\n",
    "\n",
    "    return obstacles\n",
    "\n",
    "obstacles = get_obstacles()  # Get the list of obstacles\n",
    "\n",
    "def distance_point_to_segment(p, a, b):\n",
    "    \"\"\" \n",
    "    Calculate the distance from point p to the line segment defined by points a and b.\n",
    "    Parameters:\n",
    "    - p: Point (x, y) as a numpy array\n",
    "    - a: Start point of the segment (x, y) as a numpy array\n",
    "    - b: End point of the segment (x, y) as a numpy array\n",
    "    Returns:\n",
    "    - Distance from point p to the segment ab.\n",
    "    \"\"\"\n",
    "    ap = p - a # Vector from a to p\n",
    "    ab = b - a # Vector from a to b\n",
    "    t = np.dot(ap, ab) / (np.dot(ab, ab) + 1e-8) # Project p onto line ab\n",
    "    # 1e-8 is added to avoid division by zero\n",
    "    t = np.clip(t, 0.0, 1.0) # Clamp projection to the segment [a, b]\n",
    "    closest = a + t * ab # Closest point on the segment to p\n",
    "    return np.linalg.norm(p - closest) # Euclidean distance\n",
    "\n",
    "def is_collision(path, obstacles, robot_radius=RADIUS):\n",
    "    \"\"\" \n",
    "    Check if the path collides with any obstacles.\n",
    "    Parameters:\n",
    "    - path: List of points representing the path [(x1, y1), (x2, y2), ...]\n",
    "    - obstacles: List of obstacles, each defined by a tuple (start, end, radius)\n",
    "                 where start and end are points defining the obstacle segment\n",
    "                 and radius is the radius of the obstacle.\n",
    "    - robot_radius: Radius of the robot (default is 1.0)\n",
    "    Returns:\n",
    "    - True if the path collides with any obstacle, False otherwise.\n",
    "    \"\"\"\n",
    "    for (x, y) in path:\n",
    "        for (start, end, radius) in obstacles:\n",
    "            distance = distance_point_to_segment(np.array([x, y]), np.array(start), np.array(end))\n",
    "            if distance < (robot_radius + radius):\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization-Based Local Planner (Ignoring Obstacles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def compute_final_state(start, v, omega, t):\n",
    "    \"\"\"\n",
    "    Function to compute the final state of the robot given the initial state,\n",
    "    linear velocity, angular velocity, and time duration.\n",
    "    \n",
    "    Parameters:\n",
    "    - start: Initial state [x0, y0, theta0]\n",
    "    - v: Linear velocity\n",
    "    - omega: Angular velocity\n",
    "    - t: Time duration\n",
    "    Returns:\n",
    "    - Final state [x, y, theta]\n",
    "    \"\"\"\n",
    "    \n",
    "    x0, y0, theta0 = start\n",
    "    if np.isclose(omega, 0.0):\n",
    "        x = x0 + v * t * np.cos(theta0)\n",
    "        y = y0 + v * t * np.sin(theta0)\n",
    "        theta = theta0\n",
    "    else:    \n",
    "        theta = theta0 + omega * t\n",
    "        theta = np.arctan2(np.sin(theta), np.cos(theta))  # Normalize\n",
    "        x = x0 + (v / omega) * (np.sin(theta) - np.sin(theta0))\n",
    "        y = y0 + (v / omega) * (np.cos(theta0) - np.cos(theta))\n",
    "    return np.array([x, y, theta])\n",
    "\n",
    "def local_planner(start, goal, robot_radius=RADIUS):\n",
    "    \"\"\"\n",
    "    Local planner to compute the optimal linear and angular velocities\n",
    "    to reach a goal position while ignoring obstacles.\n",
    "    Uses optimization to find the best velocities and time duration.\n",
    "    \n",
    "    Parameters:\n",
    "    - start: Initial state [x0, y0, theta0]\n",
    "    - goal: Goal state [x_goal, y_goal, theta_goal]\n",
    "    - robot_radius: Radius of the robot (default is 1.0)\n",
    "    Returns:\n",
    "    - v_opt: Optimal linear velocity\n",
    "    - omega_opt: Optimal angular velocity\n",
    "    - t_opt: Optimal time duration\n",
    "    - path: List of positions (x, y) along the path to the goal\n",
    "    \"\"\"\n",
    "    def objective(variables):\n",
    "        v, omega, t = variables\n",
    "        final_state = compute_final_state(start, v, omega, t)\n",
    "        error = final_state[:2] - goal[:2]\n",
    "        return np.sum(error**2) + 0.1 * t  # penalize time and position error\n",
    "    \n",
    "    dx = goal[0] - start[0]\n",
    "    dy = goal[1] - start[1]\n",
    "    distance = np.hypot(dx, dy)\n",
    "    initial_theta = start[2]\n",
    "    # initial_v = distance / 1.0 if distance > 0 else 0.0\n",
    "    direction = np.sign(np.cos(initial_theta - start[2]))  # is goal roughly forward or backward\n",
    "    initial_v = direction * distance / 1.0\n",
    "    initial_omega = (initial_theta - start[2]) / 1.0\n",
    "    initial_guess = [initial_v, initial_omega, 1.0]\n",
    "    \n",
    "    bounds = [(-3.0, 3.0), (-2.0, 2.0), (0.1, 5.0)] \n",
    "    \n",
    "    result = minimize(objective, initial_guess, bounds=bounds, method='SLSQP')\n",
    "    \n",
    "    if not result.success:        \n",
    "        print(f\"Local planner failed! Start: {start}, Goal: {goal}\")\n",
    "        return 0.0, 0.0, 0.0, []\n",
    "    \n",
    "    v_opt, omega_opt, t_opt = result.x\n",
    "    dt = 0.1\n",
    "    time_steps = int(t_opt / dt)\n",
    "    path = []\n",
    "    current_state = np.array(start)\n",
    "    for _ in range(time_steps):\n",
    "        current_state = discrete_dynamics(current_state, [v_opt, omega_opt], dt, model_mismatch=False)\n",
    "        path.append(current_state[:2])\n",
    "    \n",
    "    if path and not is_collision(path, obstacles, robot_radius):\n",
    "        return v_opt, omega_opt, t_opt, path\n",
    "    return 0.0, 0.0, 0.0, []  # Return zero velocities if path collides with obstacles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import KDTree\n",
    "\n",
    "class Node:\n",
    "    \"\"\"\n",
    "    Node class for dijkstra search\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, x, y, cost, parent_index):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.cost = cost\n",
    "        self.parent_index = parent_index\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.x) + \",\" + str(self.y) + \",\" +\\\n",
    "               str(self.cost) + \",\" + str(self.parent_index)\n",
    "               \n",
    "def sample_points(sx, sy, gx, gy, robot_radius, obstacles, rng=None):\n",
    "    \"\"\"\n",
    "    This function samples points in the environment while avoiding obstacles.\n",
    "    It generates random points within a defined range and checks for collisions\n",
    "    with obstacles. The function returns a list of sampled points including the\n",
    "    start and goal positions.\n",
    "    Parameters:\n",
    "    - sx: Start x-coordinate\n",
    "    - sy: Start y-coordinate\n",
    "    - gx: Goal x-coordinate\n",
    "    - gy: Goal y-coordinate\n",
    "    - robot_radius: Radius of the robot\n",
    "    - obstacles: List of obstacles defined as tuples (start, end, radius)\n",
    "    - rng: Random number generator (optional)\n",
    "    Returns:\n",
    "    - sample_x: List of 500 sampled x-coordinates + [sx, gx]\n",
    "    - sample_y: List of 500 sampled y-coordinates + [sy, gy]\n",
    "    \"\"\"\n",
    "    min_x, max_x = -5, 5\n",
    "    min_y, max_y = -5, 5\n",
    "    sample_x, sample_y = [], []\n",
    "    rng = np.random.default_rng() if rng is None else rng\n",
    "    while len(sample_x) < NUMBER_OF_NODES: # number of sample points\n",
    "        tx = rng.uniform(min_x, max_x)\n",
    "        ty = rng.uniform(min_y, max_y)\n",
    "        if not is_collision([(tx, ty)], obstacles, robot_radius+0.2): # add a small margin\n",
    "            sample_x.append(tx)\n",
    "            sample_y.append(ty)\n",
    "    sample_x += [sx, gx]\n",
    "    sample_y += [sy, gy]\n",
    "    return sample_x, sample_y\n",
    "\n",
    "def generate_road_map(sample_x, sample_y, robot_radius, obstacles):\n",
    "    \"\"\"\n",
    "    Generate a road map (graph) from sampled points. (PRM)\n",
    "    This function creates a road map by connecting sampled points with edges\n",
    "    based on local planning. It uses a KDTree for efficient nearest neighbor search\n",
    "    and checks for collisions with obstacles. Each sampled point is connected to\n",
    "    its nearest neighbors, forming a graph structure.\n",
    "    Parameters:\n",
    "    - sample_x: List of sampled x-coordinates\n",
    "    - sample_y: List of sampled y-coordinates\n",
    "    - robot_radius: Radius of the robot\n",
    "    - obstacles: List of obstacles defined as tuples (start, end, radius)\n",
    "    Returns:\n",
    "    - road_map: List of edges for each sampled point, where each edge is a list of indices\n",
    "                of connected points. Each index corresponds to a point in sample_x and sample_y.\n",
    "    \"\"\"\n",
    "    road_map = []\n",
    "    sample_kd_tree = KDTree(np.vstack((sample_x, sample_y)).T)\n",
    "    # intialize fast nearest-neighbor lookup from all sample points\n",
    "    for i in range(len(sample_x)):\n",
    "        ix, iy = sample_x[i], sample_y[i]\n",
    "        dists, indexes = sample_kd_tree.query([ix, iy], k=len(sample_x))\n",
    "        # indexes = indices of all points sorted by distance\n",
    "        edge_id = []\n",
    "        for j in indexes[1:]: # skip the first point (itself)\n",
    "            nx, ny = sample_x[j], sample_y[j]\n",
    "            start_theta = np.arctan2(ny - iy, nx - ix) # angle to the point\n",
    "            goal_theta = start_theta # orientation of the robot\n",
    "            start = [ix, iy, start_theta]\n",
    "            goal = [nx, ny, goal_theta]\n",
    "            _, _, _, path = local_planner(start, goal, robot_radius)\n",
    "            if path and not is_collision(path, obstacles, robot_radius):\n",
    "                edge_id.append(j)\n",
    "            if len(edge_id) >= NUMBER_OF_NEIGHBORS:\n",
    "                break\n",
    "        road_map.append(edge_id)\n",
    "    return road_map\n",
    "\n",
    "def dijkstra_planning(sx, sy, gx, gy, road_map, sample_x, sample_y):\n",
    "    \"\"\" \n",
    "    Dijkstra's algorithm for path planning.\n",
    "    This function implements Dijkstra's algorithm to find the shortest path\n",
    "    from the start node to the goal node in a road map. It uses a priority queue\n",
    "    to explore nodes based on their cost and maintains a closed set of visited nodes.\n",
    "    Parameters:\n",
    "    - sx: Start x-coordinate\n",
    "    - sy: Start y-coordinate\n",
    "    - gx: Goal x-coordinate\n",
    "    - gy: Goal y-coordinate\n",
    "    - road_map: List of edges for each sampled point, where each edge is a list of indices\n",
    "    - sample_x: List of sampled x-coordinates\n",
    "    - sample_y: List of sampled y-coordinates\n",
    "    Returns:\n",
    "    - rx: List of x-coordinates of the path from start to goal\n",
    "    - ry: List of y-coordinates of the path from start to goal\n",
    "    \"\"\"\n",
    "    start_node = Node(sx, sy, 0.0, -1) # x, y, cost, parent_index\n",
    "    goal_node = Node(gx, gy, 0.0, -1)\n",
    "    # open = unvisited nodes, closed = visited nodes\n",
    "    open_set, closed_set = {len(sample_x)-2: start_node}, {} # start node and empty closed set\n",
    "    \n",
    "    # Continue until all reachable nodes are visited or goal is found\n",
    "    while open_set:\n",
    "        c_id = min(open_set, key=lambda k: open_set[k].cost)\n",
    "        current = open_set[c_id]\n",
    "        if c_id == len(sample_x)-1:\n",
    "            rx, ry = [current.x], [current.y]\n",
    "            while current.parent_index != -1:\n",
    "                current = closed_set[current.parent_index]\n",
    "                rx.append(current.x)\n",
    "                ry.append(current.y)\n",
    "            return rx[::-1], ry[::-1]\n",
    "        del open_set[c_id] # remove current node from open set\n",
    "        closed_set[c_id] = current # add current node to closed set\n",
    "        for n_id in road_map[c_id]: # iterate over neighbors\n",
    "            dx = sample_x[n_id] - current.x\n",
    "            dy = sample_y[n_id] - current.y\n",
    "            d = np.hypot(dx, dy)\n",
    "            node = Node(sample_x[n_id], sample_y[n_id], current.cost + d, c_id)\n",
    "            if n_id in closed_set:\n",
    "                continue\n",
    "            if n_id in open_set:\n",
    "                if open_set[n_id].cost > node.cost:\n",
    "                    open_set[n_id] = node\n",
    "            else:\n",
    "                open_set[n_id] = node\n",
    "    return [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full motion planner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle, Rectangle\n",
    "import matplotlib.transforms as transforms\n",
    "\n",
    "class MotionPlanner:\n",
    "    def __init__(self, start, goal, obstacles):\n",
    "        self.obstacles = obstacles\n",
    "        self.robot_radius = RADIUS\n",
    "        self.sample_x, self.sample_y = sample_points(start[0], start[1], goal[0], goal[1], self.robot_radius, obstacles)\n",
    "        self.road_map = generate_road_map(self.sample_x, self.sample_y, self.robot_radius, obstacles)\n",
    "        self.global_path_x, self.global_path_y = dijkstra_planning(start[0], start[1], goal[0], goal[1], self.road_map, self.sample_x, self.sample_y)\n",
    "        self.current_idx = 0\n",
    "        \n",
    "        self.ref_traj = None\n",
    "        self.ref_traj = self.reference_trajectory()\n",
    "        self.ref_idx = 0\n",
    "        self.start_time = None  # Initialize start time for reference trajectory        \n",
    "        \n",
    "        self.actual_path_x = [(start[0], start[1])]\n",
    "\n",
    "    def basic_control(self, x, y, theta):\n",
    "        \"\"\"\n",
    "        Returns the control inputs (linear and angular velocities) for the robot\n",
    "        to follow the global path towards the next waypoint.\n",
    "        If the robot is close enough to the next waypoint, it moves to the next one.\n",
    "        Parameters:\n",
    "        - x: Current x position of the robot\n",
    "        - y: Current y position of the robot\n",
    "        - theta: Current orientation of the robot (in radians)\n",
    "        Returns:\n",
    "        - v: Linear velocity to apply\n",
    "        - omega: Angular velocity to apply\n",
    "        \"\"\"\n",
    "        if self.current_idx >= len(self.global_path_x) - 1:\n",
    "            return 0.0, 0.0\n",
    "        self.actual_path_x.append((x, y))\n",
    "        if np.linalg.norm([x - self.global_path_x[-1], y - self.global_path_y[-1]]) < 0.15:\n",
    "            # print(\"Reached the goal! Stopping.\")\n",
    "            return 0.0, 0.0\n",
    "        \n",
    "        target_x = self.global_path_x[self.current_idx + 1]\n",
    "        target_y = self.global_path_y[self.current_idx + 1]\n",
    "        \n",
    "        # Calculate angle to target\n",
    "        target_angle = np.arctan2(target_y - y, target_x - x)\n",
    "        angle_error = target_angle - theta\n",
    "        \n",
    "        # Pure rotation phase if misaligned (only for first waypoint)\n",
    "        if (self.current_idx == 0 and np.abs(angle_error) > 0.2):  # 11.5 degrees\n",
    "            omega = np.clip(2.0 * angle_error, -4.0, 4.0)\n",
    "            return 0.0, omega  # Rotate in place\n",
    "    \n",
    "\n",
    "        start = [x, y, theta]\n",
    "        goal_theta = np.arctan2(target_y - y, target_x - x)\n",
    "        goal = [target_x, target_y, goal_theta] \n",
    "        \n",
    "        # try to find a valid path using local planner (there exist one but sometimes it generates a collision)\n",
    "        v, omega, _, path = local_planner(start, goal, self.robot_radius)\n",
    "        i = 0\n",
    "        while (path and is_collision(path, self.obstacles, self.robot_radius)) and (i < 10):\n",
    "            i += 1\n",
    "            v, omega, _, path = local_planner(start, goal, robot_radius=RADIUS)\n",
    "        \n",
    "        if v is None or omega is None:\n",
    "            print(\"Invalid control (None detected)! Using zeros.\")            \n",
    "            return 0.0, 0.0  # Stop the robot\n",
    "        if np.hypot(target_x - x, target_y - y) < 0.3:  # If close enough to the next waypoint\n",
    "            # if not (self.current_idx + 2 < len(self.global_path_x)):\n",
    "            #     # print(\"Reached the goal waypoint! Stopping.\")\n",
    "            # else:\n",
    "                # print(f\"Reached waypoint {self.current_idx}. Advancing to next.\")\n",
    "                # print(f\"Current location: ({x:.2f}, {y:.2f}). Next goal location: ({self.global_path_x[self.current_idx + 2]:.2f}, {self.global_path_y[self.current_idx + 2]:.2f})\")\n",
    "                \n",
    "            self.current_idx += 1\n",
    "        return v, omega\n",
    "    \n",
    "    def reference_trajectory(self):\n",
    "        \"\"\" \n",
    "        Generates a full reference trajectory using local planner between consecutive waypoints\n",
    "        Returns list of (x, y, theta, t) states with timestamps\n",
    "        \"\"\"\n",
    "        if self.ref_traj is not None:\n",
    "            return self.ref_traj\n",
    "        \n",
    "        full_trajectory = []\n",
    "        current_time = 0.0\n",
    "        current_state = np.array([self.global_path_x[0], self.global_path_y[0], START[2]])  # Initial orientation\n",
    "        \n",
    "        # Create trajectory for each segment of the global path\n",
    "        for i in range(len(self.global_path_x)-1):\n",
    "            start = current_state.copy()\n",
    "            goal_theta = np.arctan2(self.global_path_y[i+1] - start[1], \n",
    "                                   self.global_path_x[i+1] - start[0])\n",
    "            goal = [self.global_path_x[i+1], self.global_path_y[i+1], goal_theta]\n",
    "            \n",
    "            # Get local path from planner\n",
    "            v, omega, t, path = local_planner(start, goal, self.robot_radius) \n",
    "            j = 0\n",
    "            while (path and is_collision(path, self.obstacles, self.robot_radius)) and (j < 10):\n",
    "                j += 1\n",
    "                theta_inverse = np.arctan2(np.sin(theta+(j* np.pi/2)), np.cos(theta+ (j*np.pi/2)))\n",
    "                v, omega, t, path = local_planner(start, goal, robot_radius=RADIUS)\n",
    "            \n",
    "            if len(path) == 0:\n",
    "                continue\n",
    "                \n",
    "            # Simulate trajectory with timestamps\n",
    "            dt = 0.1\n",
    "            time_steps = int(t / dt)\n",
    "            current_state_sim = start.copy()\n",
    "            for _ in range(time_steps):\n",
    "                current_state_sim = discrete_dynamics(current_state_sim, [v, omega], dt, model_mismatch=False)\n",
    "                full_trajectory.append({\n",
    "                    'x': current_state_sim[0],\n",
    "                    'y': current_state_sim[1],\n",
    "                    'theta': current_state_sim[2],\n",
    "                    't': current_time,\n",
    "                    'v': v,\n",
    "                    'omega': omega\n",
    "                })\n",
    "                current_time += dt\n",
    "            \n",
    "            current_state = current_state_sim.copy()\n",
    "        \n",
    "        self.ref_traj = full_trajectory\n",
    "        return full_trajectory\n",
    "    \n",
    "    def plot_ref_traj(self):\n",
    "        \"\"\"\n",
    "        Plots the reference trajectory generated by the reference_trajectory method.\n",
    "        \"\"\"\n",
    "        if self.ref_traj is None:\n",
    "            print(\"Reference trajectory not generated yet.\")\n",
    "            return\n",
    "        \n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.axis(\"equal\")\n",
    "        \n",
    "        # Extract x, y, theta from the reference trajectory\n",
    "        x = [state['x'] for state in self.ref_traj]\n",
    "        y = [state['y'] for state in self.ref_traj]\n",
    "        \n",
    "        plt.plot(x, y, label=\"Reference Trajectory\", color='blue')\n",
    "        plt.scatter(self.global_path_x, self.global_path_y, color='red', label=\"Global Path Waypoints\")\n",
    "        \n",
    "        # Plot obstacles\n",
    "        for (start, end, radius) in self.obstacles:\n",
    "            if start == end:  # Circle (cylinder or tower)\n",
    "                circle = Circle(start, radius, color=\"red\", alpha=0.5)\n",
    "                plt.gca().add_patch(circle)\n",
    "            else:\n",
    "                dx = end[0] - start[0]\n",
    "                dy = end[1] - start[1]\n",
    "                length = np.hypot(dx, dy)\n",
    "                angle = np.arctan2(dy, dx)\n",
    "                center_x = (start[0] + end[0]) / 2\n",
    "                center_y = (start[1] + end[1]) / 2\n",
    "\n",
    "                # Create unrotated rectangle\n",
    "                box = Rectangle(\n",
    "                    (-length / 2, -radius),  # lower-left corner (local coords)\n",
    "                    width=length,\n",
    "                    height=radius * 2,\n",
    "                    color=\"red\",\n",
    "                    alpha=0.5\n",
    "                )\n",
    "\n",
    "                # Rotate and move the rectangle to its position\n",
    "                t = transforms.Affine2D().rotate(angle).translate(center_x, center_y) + plt.gca().transData\n",
    "                box.set_transform(t)\n",
    "                plt.gca().add_patch(box)\n",
    "        \n",
    "        plt.title(\"Reference Trajectory\")\n",
    "        plt.xlabel(\"X Position\")\n",
    "        plt.ylabel(\"Y Position\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "    \n",
    "    def reference_trajectory_control(self, x, y, theta):\n",
    "        \"\"\"\n",
    "        Takes the current state of the robot and returns the control inputs\n",
    "        (linear and angular velocities) to follow the reference trajectory.\n",
    "        Parameters:\n",
    "        - x: Current x position of the robot\n",
    "        - y: Current y position of the robot\n",
    "        - theta: Current orientation of the robot (in radians)\n",
    "        Returns:\n",
    "        - v: Linear velocity to apply\n",
    "        - omega: Angular velocity to apply\n",
    "        \"\"\"\n",
    "        # Store actual path\n",
    "        self.actual_path_x.append((x, y))\n",
    "        \n",
    "        # Early exit if at goal\n",
    "        if np.linalg.norm([x - GOAL[0], y - GOAL[1]]) < 0.15:\n",
    "            return 0.0, 0.0\n",
    "\n",
    "        # Controller gains (adjusted for better stability)\n",
    "        k1 = 1.0\n",
    "        k2 = 1.5\n",
    "        k3 = 2.5\n",
    "        EPS = 1e-8  # Anti-division-by-zero\n",
    "\n",
    "        # Find nearest reference point using Euclidean distance\n",
    "        current_pos = np.array([x, y])\n",
    "        ref_points = np.array([[p['x'], p['y']] for p in self.ref_traj])\n",
    "        distances = np.linalg.norm(ref_points - current_pos, axis=1)\n",
    "        closest_idx = np.argmin(distances)\n",
    "        \n",
    "        ref_state = self.ref_traj[closest_idx]\n",
    "\n",
    "        # Get reference values\n",
    "        x_d = ref_state['x']\n",
    "        y_d = ref_state['y']\n",
    "        phi_d = ref_state['theta']\n",
    "        v_d = ref_state['v']\n",
    "        omega_d = ref_state['omega']\n",
    "\n",
    "        # Error transformation matrix (fixed orientation)\n",
    "        R = np.array([\n",
    "            [np.cos(phi_d), np.sin(phi_d), 0],\n",
    "            [-np.sin(phi_d), np.cos(phi_d), 0],\n",
    "            [0, 0, 1]\n",
    "        ])\n",
    "        \n",
    "        # Compute errors\n",
    "        pose_error = np.array([x - x_d, y - y_d, theta - phi_d])\n",
    "        x_e, y_e, theta_e = R @ pose_error\n",
    "        \n",
    "        # theta_e = np.clip(theta_e, -np.deg2rad(90), np.deg2rad(90))  # Prevent division issues\n",
    "\n",
    "        # Modified control law with feedforward and protection\n",
    "        try:\n",
    "            v = (v_d - k1 * abs(v_d) * (x_e + y_e * np.tan(theta_e))) / (np.cos(theta_e) + EPS)\n",
    "            omega = omega_d - ((k2 * v_d * y_e + k3 * abs(v_d) * np.tan(theta_e)) * (np.cos(theta_e)**2))\n",
    "        except ZeroDivisionError:\n",
    "            v, omega = v_d, omega_d\n",
    "        \n",
    "        \n",
    "        # print(f\"v_d: {v_d:.2f}, omega_d: {omega_d:.2f}\")\n",
    "        # print(f\"x_e: {x_e:.2f}, y_e: {y_e:.2f}, theta_e: {np.degrees(theta_e):.2f}째 , v: {v:.2f}, omega: {omega:.2f}\")\n",
    "        # print(f\"Ref Traj: t={ref_state['t']:.1f}, v_d={ref_state['v']:.2f}, omega_d={ref_state['omega']:.2f}\")\n",
    "        \n",
    "        # Higher limits for velocities\n",
    "        # (The reference trajectory could be planned using not-quite-extremal controls, capped at v=3 and omega=2)\n",
    "        MAX_V = 5\n",
    "        MAX_OMEGA = 4\n",
    "        v = np.clip(v, -MAX_V, MAX_V)\n",
    "        omega = np.clip(omega, -MAX_OMEGA, MAX_OMEGA)\n",
    "\n",
    "        # # Add low-pass filter to control outputs\n",
    "        # if self.last_controls is None:\n",
    "        #     self.last_controls = np.array([v, omega])\n",
    "        # else:\n",
    "        #     alpha = 0.2  # Filter coefficient\n",
    "        #     self.last_controls = alpha * np.array([v, omega]) + (1-alpha) * self.last_controls\n",
    "        #     v, omega = self.last_controls\n",
    "\n",
    "        return float(v), float(omega)\n",
    "    \n",
    "    def plot_road_map(self):\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.axis(\"equal\")\n",
    "\n",
    "        # Plot roadmap nodes\n",
    "        plt.scatter(self.sample_x, self.sample_y, s=5, c=\"blue\", label=\"Sample Points\")\n",
    "\n",
    "        # Plot roadmap edges\n",
    "        for i, neighbors in enumerate(self.road_map):\n",
    "            ix, iy = self.sample_x[i], self.sample_y[i]\n",
    "            for j in neighbors:\n",
    "                jx, jy = self.sample_x[j], self.sample_y[j]\n",
    "                plt.plot([ix, jx], [iy, jy], \"gray\", linewidth=0.5)\n",
    "\n",
    "        # Plot obstacles\n",
    "        for (start, end, radius) in self.obstacles:\n",
    "            if start == end:  # Circle (cylinder or tower)\n",
    "                circle = Circle(start, radius, color=\"red\", alpha=0.5)\n",
    "                plt.gca().add_patch(circle)\n",
    "            else:\n",
    "                dx = end[0] - start[0]\n",
    "                dy = end[1] - start[1]\n",
    "                length = np.hypot(dx, dy)\n",
    "                angle = np.arctan2(dy, dx)\n",
    "                center_x = (start[0] + end[0]) / 2\n",
    "                center_y = (start[1] + end[1]) / 2\n",
    "\n",
    "                # Create unrotated rectangle\n",
    "                box = Rectangle(\n",
    "                    (-length / 2, -radius),  # lower-left corner (local coords)\n",
    "                    width=length,\n",
    "                    height=radius * 2,\n",
    "                    color=\"red\",\n",
    "                    alpha=0.5\n",
    "                )\n",
    "\n",
    "                # Rotate and move the rectangle to its position\n",
    "                t = transforms.Affine2D().rotate(angle).translate(center_x, center_y) + plt.gca().transData\n",
    "                box.set_transform(t)\n",
    "                plt.gca().add_patch(box)\n",
    "            \n",
    "        # Plot global path\n",
    "        plt.plot(self.global_path_x, self.global_path_y, \"b-\", linewidth=2, label=\"Global Path\")\n",
    "\n",
    "        # Plot start and goal\n",
    "        plt.plot(self.sample_x[-2], self.sample_y[-2], \"go\", label=\"Start\", markersize=8)\n",
    "        plt.plot(self.sample_x[-1], self.sample_y[-1], \"ro\", label=\"Goal\", markersize=8)\n",
    "\n",
    "        plt.legend()\n",
    "        plt.title(\"PRM roadmap with obstacles\")\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_actual_path(self):\n",
    "        \"\"\"\n",
    "        Plots the actual path taken by the robot during the simulation.\n",
    "        \"\"\"\n",
    "        if not self.actual_path_x:\n",
    "            print(\"No actual path recorded.\")\n",
    "            return\n",
    "        \n",
    "        actual_x, actual_y = zip(*self.actual_path_x)\n",
    "        \n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.axis(\"equal\")\n",
    "        \n",
    "        # Plot actual path\n",
    "        plt.plot(actual_x, actual_y, label=\"Actual Path\", color='green')\n",
    "        \n",
    "        # Plot obstacles\n",
    "        for (start, end, radius) in self.obstacles:\n",
    "            if start == end:  # Circle (cylinder or tower)\n",
    "                circle = Circle(start, radius, color=\"red\", alpha=0.5)\n",
    "                plt.gca().add_patch(circle)\n",
    "            else:\n",
    "                dx = end[0] - start[0]\n",
    "                dy = end[1] - start[1]\n",
    "                length = np.hypot(dx, dy)\n",
    "                angle = np.arctan2(dy, dx)\n",
    "                center_x = (start[0] + end[0]) / 2\n",
    "                center_y = (start[1] + end[1]) / 2\n",
    "\n",
    "                # Create unrotated rectangle\n",
    "                box = Rectangle(\n",
    "                    (-length / 2, -radius), \n",
    "                    width=length,\n",
    "                    height=radius * 2,\n",
    "                    color=\"red\",\n",
    "                    alpha=0.5\n",
    "                )\n",
    "\n",
    "                # Rotate and move the rectangle to its position\n",
    "                t = transforms.Affine2D().rotate(angle).translate(center_x, center_y) + plt.gca().transData\n",
    "                box.set_transform(t)\n",
    "                plt.gca().add_patch(box)\n",
    "        \n",
    "        plt.legend()\n",
    "        plt.title(\"Actual path taken by the robot\")\n",
    "        plt.xlabel(\"X Position\")\n",
    "        plt.ylabel(\"Y Position\")\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "# Initialize planner with start and goal\n",
    "start = START\n",
    "goal = GOAL\n",
    "obstacles = get_obstacles()\n",
    "planner = MotionPlanner(start, goal, obstacles)\n",
    "planner.plot_road_map()\n",
    "planner.plot_ref_traj()\n",
    "\n",
    "def controller(x, y, theta, z):\n",
    "    # return planner.reference_trajectory_control(x, y, theta)\n",
    "    return planner.basic_control(x, y, theta)\n",
    "\n",
    "\n",
    "simulation(controller, mismatch=False)\n",
    "\n",
    "planner.plot_actual_path()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: motion planner\n",
    "In part 1, the assignment consited of designing a motion planner to generate a reference path or trajectory to move the robot from configuration A to a configuration B. Both configurations could be of own choice. The motion planner had to consists three essential parts: an optimization-based local motion planner, a collision checker and a global motion planning using the probabalistic roadmap (PRM) algorithm.\\\n",
    "\\\n",
    "The program above works as follows:\\\n",
    "\\\n",
    "The execution of the program starts by initializing a few parameters like the robot radius (to avoid collision, calculated from the URDF file), starting point, goal coordinates, seed number (for random obstacle generation), number of random nodes (for PRM algoritm) and number of neighbors to connect to (for PRM algoritm). The initial position of the robot, the obstacles and the system boundaries are vizualized. Then, the defintions of the the implemented functions and classes follow, after which the execution of the motion planner can start. The obstacles (walls and random generated obstacles) are saved to be accessble by the collision checker.\\\n",
    "\\\n",
    "The MotionPlanner is initialized, this consists of:\n",
    "* Generating a roadmap using the PRM algorithm:\n",
    "  * Generating 1000 sample points. These sample points are only kept if they are accesible by the robot, i.e. the euclidian distance from the sample coordinates to the nearest obstacle is smaller than the radius of the robot. This way the robot can access every sample point in every possible pose.\n",
    "  * Connecting the nodes with edges if the local planner can find a path between the two nodes without collision with any of the obstacles. \n",
    "  * Using the Dijkstra algorithm to find the shortes path (in euclidian distance) form START to GOAL. This generates the global path. This path consists of waypoints, i.e. nodes that are connected by an edge.\n",
    "\n",
    "* When the global path is created, the local planner can use these waypoints to generate a reference trajectory. This is the path the robot should follow if there was no model mismatch. \n",
    "\n",
    "* Now, the controller comes into play. The robot starts at its initial position and the local planner finds a path to the next waypoint. The local planner returns the optimal velocity $v$ and rotational velocity $\\omega$ to execute the found path.\n",
    "\n",
    "* The output from the controller is passed into the simulator functions, which \"executes\" the movement for one 0.1 $s$. Then, the new position and next waypoint are given back to the motion planner, which checks if the robor is near the current goal waypoint. If the robot is, the next waypoint becomes the goal.\n",
    "\n",
    "* These steps loop until the robot is at the GOAL waypoint, after which the simulation stops.\\\n",
    "\n",
    "When implementing en testing this pipeline, some issues were found and adressed.\n",
    "For the motion planner, the following design choices were made:\n",
    "1) The goal $\\theta$ was not penalized because the distance between two waypoints was too short. The optimizer had to find extreme values to find a suitable path. If for example, two way points are very close but the goal angle was orthogonal to the initial angle, the robot had to take a big detour to end in the goal angle.\n",
    "\n",
    "2) To find if their was a path between two nodes (during the roadmap generation), the initial orientation ($\\theta$) was chosen to be the direction of the line that connects the two nodes. This way, we could be certain there was a possible path between the two nodes. Because the robot has a two parallel wheel differential drive, the robot can turn in place. So it can always take on the right pose before advancing. This means, even when the robot was faced towards a wall with an obstacle directly behind it, it could still navigate out of it by turning 90째 first. With this approach, all possible positions and paths could be found in the roadmap generation.\n",
    "\n",
    "3) The issue above also had to be addressed in the motion planning when using the local planner during simulation. A partial solution was to check the orientation at the start. If the angle between the starting orientation and the line form start to next waypoint was more than 11.5째, the robot would first turn in place until the angle was below 11.5째. After advancing, the local planner calculates the optimal path every 0.1 $s$. This meant reference trajectories like the ones below in the center graph, are smoothened out. This happens because the local planner only calculates the path between the the current position and the next waypoint. So when the robot turn in place and makes a small angle with the direction to the next waypoint, the calculated local path is just a straight line. \n",
    "\n",
    "4) As the middle graph in the picture below also shows, because the roadmap generator uses optimal starting angles to find collision-free paths and when the actual orientation of the robot is orthogonal to this optimal angle, this can cause issues in the actual reference path generation. This issue is again solved with the use of the initial rotation in place mention above.\n",
    "\n",
    "5) The bounds for the optimizer in the local planner were limited because unlimited bounds (which also can cause extreme velocities and angular velocities) caused \"glitching\" of the robot. In some situations, it found two equal solutions (two half circles) because the robot can go forwards and backwards. This issue was further addressed by checking the angle of the current pose of the robot. If the front was more faced towards the next goal, the initial velocity guess was positive. If the back was faced towards the goal, a negative initial velocity was guessed. \n",
    "\n",
    "6) As the first graph in the picture below shows, sometimes the shortes path was not found. In the graph below, the passage around coordinate (-0.75, -2.5) was large enough for the robot to be able to pass. However, because of the random sampling, if the two nodes were not close enough or not low enough, the path was not found. This can possibly be improved by using more samples.\n",
    "\n",
    "<div style=\"width: 100vw; display: flex;\">\n",
    "  <img src=\"PRM_example.png\" alt=\"drawing\" style=\"width: 30%;\" />\n",
    "  <img src=\"bad_trajectory.png\" alt=\"drawing\" style=\"width: 30%;\" />\n",
    "  <img src=\"actual_path.png\" alt=\"drawing\" style=\"width: 30%;\" />\n",
    "</div>\n",
    "\n",
    "7) Because the robot can rotate in place, the reference_trajectory function was later added. Instead of just finding the path from the initial pose, if no collision-free path was found, try finding a path with the robot rotated 90째.\n",
    "\n",
    "8) The local planner uses SLSQP (sequential least squares programming). This is a popular optimization method for constrained non-linear problems. It's a great choice in this situation because this optimizer handles non-linear dynamics and the low number of constrains well. $1$\n",
    "\n",
    "9) The motion planner switching the next goal/waypoint whenever the robot gets into a radius of 0.2 (euclidian distance) of the current goal/waypoints. This way, the trajectory of the robot is smoothened and the nearby waypoints can be handled as one.\n",
    "\n",
    "10) Later, the code was adjusted to implement the following change: instead of still making a refence path even when a collision occurs (as you can see in the image above), return an empty path. This way, it was certain that collisions would be avoided. this came with the following problem: now some sample points that are visitable by the robot are only visitable in a certain direction (parallel to the wall) because otherwise, the robot could not turn fast enough to avoid collision. This made the reference trajectory stop at this point. To address this problem, a small margin of 0.1 was added when making sampling points. This way, all sample points are certainly visitable from multiple directions. This changed the above output to the one below. The figure shows that less places are accessible to the robot now, but the created paths are certainly collision-free. If a collision-free path exists from the starting point, it will be found. On the left side, it shows that when the robot is faced towards the wall, it can't turn fast enough and so it can't find a path. On the right it shows that when the robot is face parallel to the wall, a path is found. \n",
    "\n",
    "<div style=\"width: 100vw; display: flex;\">\n",
    "  <img src=\"no_possible_path_1.png\" alt=\"drawing\" style=\"width: 22%;\" />\n",
    "  <img src=\"no_possible_path_2.png\" alt=\"drawing\" style=\"width: 22%;\" />\n",
    "  <img src=\"possible_path_1.png\" alt=\"drawing\" style=\"width: 22%;\" />\n",
    "  <img src=\"possible_path_2.png\" alt=\"drawing\" style=\"width: 22%;\" />\n",
    "\n",
    "</div>\n",
    "\n",
    "*To run the code that produces these outputs, set START at the top to the right position, set mismatch=False and return planner.basic_control(x, y, theta)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Reference trajectory tracking\n",
    "To create a trajectory tracking, model mismatching was activated. The trajectory was created using the same principles as mentioned before. The controller that tracked the trajectory and the errors from diverging from it were just taken from the book (equation 13.30 and 13.31). This gave the following results in the picture below.\n",
    "\n",
    "<div style=\"width: 100vw; display: flex;\">\n",
    "  <img src=\"reference_trajectory_1.png\" alt=\"drawing\" style=\"width: 40%;\" />\n",
    "  <img src=\"reference_trajectory_2.png\" alt=\"drawing\" style=\"width: 40%;\" />\n",
    "</div>\n",
    "\n",
    "By tuning the parameters $k1$, $k2$ and $k3$ an optimal tracker was found. $k3$ was tuned the highest because this parameter caused better heading correction (critical for path alignment). The other two parameters were initialy both 1.5 but the robot overshot sometimes so $k1$ was reduced to 1.0.\n",
    "\n",
    "*To run the code that produces these outputs, set START at the top to the right position, set mismatch=True and return planner.reference_trajectory_control(x, y, theta) at the bottom*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extended Kalman filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtendedKalmanFilter:\n",
    "    def __init__(self, initial_state, initial_covariance, process_noise, measurement_noise):\n",
    "        self.state = np.array(initial_state)  # [x, y, theta]\n",
    "        self.covariance = np.array(initial_covariance)  # 3x3 matrix\n",
    "        self.process_noise = np.array(process_noise)  # Q (3x3)\n",
    "        self.measurement_noise = np.array(measurement_noise)  # R (2x2)\n",
    "        self.H = np.array([[1, 0, 0], [0, 1, 0]])  # Measurement matrix\n",
    "\n",
    "    def predict(self, control_input, dt):\n",
    "        \"\"\"\n",
    "        Predict step using control inputs (v, omega).\n",
    "        \"\"\"\n",
    "        v, omega = control_input\n",
    "        x, y, theta = self.state\n",
    "\n",
    "        # Jacobian of motion model (A)\n",
    "        A = np.eye(3)\n",
    "        A[0, 2] = -v * np.sin(theta) * dt\n",
    "        A[1, 2] = v * np.cos(theta) * dt\n",
    "\n",
    "        # Predict state using discrete dynamics\n",
    "        self.state = discrete_dynamics(self.state, [v, omega], dt, model_mismatch=False)\n",
    "\n",
    "        # Update covariance: P = APA^T + Q\n",
    "        self.covariance = A @ self.covariance @ A.T + self.process_noise\n",
    "\n",
    "    def update(self, measurement):\n",
    "        \"\"\"\n",
    "        Update step using GPS measurement (x, y).\n",
    "        \"\"\"\n",
    "        z = np.array(measurement)\n",
    "        H = self.H\n",
    "\n",
    "        # Kalman gain: K = P H^T (H P H^T + R)^-1\n",
    "        S = H @ self.covariance @ H.T + self.measurement_noise\n",
    "        K = self.covariance @ H.T @ np.linalg.inv(S)\n",
    "\n",
    "        # Update state and covariance\n",
    "        y = z - H @ self.state\n",
    "        self.state += K @ y\n",
    "        self.covariance = (np.eye(3) - K @ H) @ self.covariance\n",
    "\n",
    "    def get_estimate(self):\n",
    "        return self.state\n",
    "\n",
    "\n",
    "def simulation_kalman(controller, mismatch=True):\n",
    "    # Simulation parameters\n",
    "    u_prev = 0.0\n",
    "    w_prev = 0.0\n",
    "    dt = 0.01  # Time step (s)\n",
    "    simulation_time = 30  # Total simulation time (s)\n",
    "    sensor_noise_stddev = 0.03  # Standard deviation of sensor noise (m)\n",
    "\n",
    "    # Initial robot position and orientation\n",
    "    x, y, theta = START  # Initial position (x, y) and orientation (theta)\n",
    "    \n",
    "    initial_state = [START[0], START[1], START[2]]  # Initial state [x, y, theta]\n",
    "    initial_covariance = np.diag([0.1, 0.1, 0.1])\n",
    "    process_noise = np.diag([1.0, 1.0, 0.05])  # Tuned based on model mismatch noise\n",
    "    measurement_noise = np.diag([0.03**2, 0.03**2])  # From sensor_noise_stddev=0.03\n",
    "    ekf = ExtendedKalmanFilter(initial_state, initial_covariance, process_noise, measurement_noise)\n",
    "\n",
    "    # Simulation loop\n",
    "    for t in np.arange(0, simulation_time, dt):\n",
    "\n",
    "        z = np.array([x,y]) + np.random.normal(0, sensor_noise_stddev, 2)  # Simulated sensor measurement with noise\n",
    "\n",
    "        # calculate control inputs\n",
    "        ekf.predict([u_prev, w_prev], dt)  # Use previous control for prediction\n",
    "        ekf.update(z)\n",
    "        x_est, y_est, theta_est = ekf.get_estimate()\n",
    "        u, w = controller(x_est, y_est, theta_est, z)  # Compute control using estimate\n",
    "        u_prev, w_prev = u, w  # Store for next prediction\n",
    "\n",
    "        # Update robot position and orientation using differential drive kinematics\n",
    "        x, y, theta = discrete_dynamics([x, y, theta], [u,w], dt, model_mismatch=mismatch)\n",
    "\n",
    "        # Normalize theta to keep it within [-pi, pi]\n",
    "        theta = np.arctan2(np.sin(theta), np.cos(theta))\n",
    "\n",
    "        # Display the robot in the visualization\n",
    "        show_robot(x, y, theta)\n",
    "        # Calculate and visualize distances to towers\n",
    "        \n",
    "        if np.linalg.norm([x - GOAL[0], y - GOAL[1]]) <= 0.2:\n",
    "            print(\"Goal reached!\")\n",
    "            break\n",
    "\n",
    "        # Pause to simulate real-time visualization\n",
    "        time.sleep(dt)\n",
    "\n",
    "# Initialize planner with start and goal\n",
    "start = START\n",
    "goal = GOAL\n",
    "show_robot(START[0], START[1], START[2])  # Show initial robot position\n",
    "obstacles = get_obstacles()\n",
    "planner = MotionPlanner(start, goal, obstacles)\n",
    "planner.actual_path_x = [(start[0], start[1])]  # Reset actual path for EKF simulation\n",
    "planner.plot_road_map()\n",
    "planner.plot_ref_traj()\n",
    "\n",
    "def controller(x, y, theta, z):\n",
    "    return planner.basic_control(x, y, theta)\n",
    "\n",
    "\n",
    "simulation_kalman(controller, mismatch=True)\n",
    "\n",
    "planner.plot_actual_path()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Estimator\n",
    "\n",
    "This implementation implements the Extended Kalman Filter (EKF) algorithm from lecture slides on probabilistic robotics. It follows the Bayes filter paradigm of estimating the robot's state recursively in the prediction (process model) and update (measurement model) phases. The EKF linearises the non-linear motion model by Jacobian $A$ (slide 53) and blends noisy GPS measurements ($z$) using a linearised measurement matrix $H$, according to the Bayesian approach to deal with uncertainty in state estimation (slides 1820).\n",
    "\n",
    "The EKF is a good solution here because it's a static environment, with a hard-coded noise level so these are correclty parameterized. Through probabilistic combination of noisy sensor data and control inputs, this application balances model prediction and world observation, demonstrating a practical application of the Bayesian filtering ideas taught in the course. Below is an example output generated by the code above.\n",
    "\n",
    "<div style=\"width: 100vw; display: flex;\">\n",
    "  <img src=\"kalman1.png\" alt=\"drawing\" style=\"width: 30%;\" />\n",
    "  <img src=\"kalman2.png\" alt=\"drawing\" style=\"width: 30%;\" />\n",
    "  <img src=\"kalman3.png\" alt=\"drawing\" style=\"width: 30%;\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: Car-like robot\n",
    "\n",
    "See other file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "1) https://mdolab-pyoptsparse.readthedocs-hosted.com/en/latest/optimizers/SLSQP.html\n",
    "2) https://github.com/AtsushiSakai/PythonRobotics/blob/master/PathPlanning/ProbabilisticRoadMap/probabilistic_road_map.py\n",
    "3) *MODERN ROBOTICS: MECHANICS, PLANNING, AND CONTROL*, (December 30, 2019).  Kevin M. Lynch and Frank C. Park. ISBN 9781107156302\n",
    "4) *Estimation and Probabilistic Robotics*, (2024). Erwin Aertbeli챘n, KULeuven"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py13roboticscourse)",
   "language": "python",
   "name": "py13roboticscourse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
