{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy provides import array and linear algebra utilities\n",
    "import numpy as np\n",
    "# casadi is a library for symbolic computation\n",
    "import casadi as ca\n",
    "# the transformations module provides functions for creating transformations\n",
    "import utils.transformations as ta\n",
    "# some libraries used for visualizations\n",
    "from example_robot_data import load\n",
    "from pinocchio.visualize import MeshcatVisualizer\n",
    "import time\n",
    "import meshcat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robotics Course : Control Exercise\n",
    "\n",
    "## Part 3 : Constraint-based robot task specification\n",
    "\n",
    "The two previous parts focussed on control (both in joint space and in task space).\n",
    "This part shifts the focus to task specification, i.e., telling the robot what it should do.\n",
    "Specifically, we will investigate *constraint-based task specification*, where the desired behaviour of the robot is specified in terms of constraints (task functions).\n",
    "Then, a feedback controller (similar to the controllers designed in part 2), is used to regulate the task functions to their desired values.\n",
    "\n",
    "A simulation environment and controller is provided, and your objective is to specify the task functions to accomplish the desired behaviour. \n",
    "\n",
    "### Load a robot and create a visualization environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can open the visualizer by visiting the following URL:\n",
      "http://127.0.0.1:7000/static/\n"
     ]
    }
   ],
   "source": [
    "robot = load(\"panda\")\n",
    "viz = MeshcatVisualizer(robot.model, robot.collision_model, robot.visual_model)\n",
    "viz.initViewer(loadModel=True)\n",
    "\n",
    "# Add floor\n",
    "material_black = meshcat.geometry.MeshPhongMaterial()\n",
    "material_black.color = int(100) * 256**2 + int(100) * 256 + int(100)\n",
    "viz.viewer['floor'].set_object(\n",
    "    meshcat.geometry.Box([1.25, 1, 0.01]), material_black)\n",
    "viz.viewer['floor'].set_transform(\n",
    "    ta.SE3_from_xyz_rpy([0.375, 0, -0.01], [0, 0, 0]))\n",
    "\n",
    "# Set initial joint angles\n",
    "q0 = np.array([-0.37, -0.88, -0.24, -2.35, -0.18,  1.47, 0.24])\n",
    "viz.display(np.append(q0, [0, 0]))\n",
    "# viz.viewer.jupyter_cell()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define CasADi functions for robot and the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load casadi function for the forward kinematics of the end effector\n",
    "# this function was generate using Pinocchio as shown in exercise 1\n",
    "T_world_ee_fn = ca.Function.load('panda_T_world_ee.casadi')\n",
    "\n",
    "# define a symbolic variable for time\n",
    "t_sym = ca.MX.sym(\"t_sym\")\n",
    "\n",
    "# define the target pose\n",
    "T_world_goal = ta.SE3_from_xyz_rpy(\n",
    "    xyz=[0.5-0.2*ca.cos(t_sym), 0, 0.5], rpy=[np.pi, 0, 0])\n",
    "\n",
    "# convert to a casadi function to evaluate numerically (or symbolically)\n",
    "T_world_goal_fn = ca.Function(\"T_world_goal_fn\", [t_sym], [\n",
    "                              T_world_goal], [\"t\"], [\"T_world_goal\"])\n",
    "\n",
    "# Define obstacle trajectory\n",
    "T_world_obstacle = ta.SE3_from_xyz_rpy(\n",
    "    xyz=[0.5, -0.3*ca.cos(1*t_sym), 0.5], rpy=[0, 0, 0])\n",
    "# convert to a casadi function to evaluate numerically (or symbolically)\n",
    "T_world_obstacle_fn = ca.Function(\"T_world_obstacle_fn\", [t_sym], [\n",
    "                                  T_world_obstacle], [\"t\"], [\"T_world_obstacle\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add frames\n",
    "viz.viewer['T_w_ee'].set_object(meshcat.geometry.triad(0.1))\n",
    "viz.viewer['T_w_ee'].set_transform(T_world_ee_fn(q0).full())\n",
    "\n",
    "# add a target frame vizualization\n",
    "viz.viewer['target'].set_object(meshcat.geometry.triad(0.1))\n",
    "viz.viewer['target'].set_transform(T_world_goal_fn(0).full())\n",
    "\n",
    "# Add obstacle\n",
    "material_obstacle = meshcat.geometry.MeshPhongMaterial()\n",
    "material_obstacle.color = int(100) * 256**2 + int(100) * 256 + int(100)\n",
    "viz.viewer['obstacle'].set_object(\n",
    "    meshcat.geometry.Sphere(0.1), material_obstacle)\n",
    "viz.viewer['obstacle'].set_transform(T_world_obstacle_fn(0).full())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The simulation loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(controller, q0):\n",
    "\n",
    "    # set parameters for the simulation\n",
    "    control_freq = 100  # hz\n",
    "    render_freq = 32  # hz\n",
    "    sim_time = 10  # sec\n",
    "\n",
    "    q = q0\n",
    "\n",
    "    for t in np.arange(0, sim_time, 1/control_freq):\n",
    "\n",
    "        # compute the joint velocities using the robot controller function\n",
    "        dq = controller(q, t)\n",
    "\n",
    "        # update the joint positions\n",
    "        # here, modeled as a perfect simulator.\n",
    "        q = q + dq * (1/control_freq)\n",
    "\n",
    "        # update the positions of the frames and obstacles\n",
    "        viz.viewer['target'].set_transform(T_world_goal_fn(t).full())\n",
    "        viz.viewer['T_w_ee'].set_transform(T_world_ee_fn(q).full())\n",
    "        viz.viewer['obstacle'].set_transform(T_world_obstacle_fn(t).full())\n",
    "\n",
    "        # update the vizualization at the correct rate\n",
    "        if t % (1/render_freq) < 1/control_freq:\n",
    "            # add two zeroes to end of q for gripper joints\n",
    "            q_robot = np.append(q, [0, 0])\n",
    "            viz.display(q_robot)\n",
    "            time.sleep(1 / (render_freq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraint-based robot task specification\n",
    "\n",
    "With the approach, the idea is to specify task functions that describe the desired behavior of the robot.\n",
    "Specifically, the following notation is used:\n",
    "$$\n",
    "e(q,t) \\xrightarrow[w]{K} e_\\text{des}(t)\n",
    "$$\n",
    "where\n",
    "- $e$ is the task function, consisting of the robot joints, $q$, and time, $t$.\n",
    "- $e_\\text{des}$ is the desired value of the task function.\n",
    "- $K^{-1}$ is the time constant with which the error should decay.\n",
    "- $w$ is a weight to indicate the importance relative to other task functions.\n",
    "\n",
    "Furthermore, it is also possible to model inequality constraint, expressed as\n",
    "$$\n",
    "h(q,t) \\xrightarrow[w]{K, \\geq} h_\\text{lower}(t)\n",
    "$$\n",
    "- $h$ is the inequality constraint, consisting of the robot joints, $q$, and time, $t$.\n",
    "- $h_\\text{lower}$ is the lower bound of the inequality constraint.\n",
    "- $K^{-1}$ is the time constant at which the controller can approach the bound of the constraint.\n",
    "- $w$ is a weight to indicate the importance relative to other task functions and inequality constraints.\n",
    "\n",
    "#### Controller\n",
    "\n",
    "Provided below is a slightly generalized version of the controller investigated in part 2. \n",
    "Specifically, at each time step the following QP is solved:\n",
    "$$\n",
    "\\begin{align*} \n",
    "        \\min_{\\dot{q}, \\epsilon} \\quad\n",
    "                & \\epsilon ^T W \\epsilon + \\mu \\dot{q}^T R \\dot{q}\n",
    "        \\\\\n",
    "        \\textrm{s.t.} \\quad\n",
    "                & \\frac{\\partial \\tilde{e} (q, t)}{\\partial q}\\dot{q}  = - K \\tilde{e}(q, t)- \\frac{\\partial \\tilde{e} (q, t)}{\\partial t} + \\epsilon_e \\\\\n",
    "                & \\frac{\\partial \\tilde{h} (q, t)}{\\partial q}\\dot{q}  \\leq - K \\tilde{h}(q, t)- \\frac{\\partial \\tilde{h} (q, t)}{\\partial t} + \\epsilon_h\n",
    "\\end{align*}\n",
    "$$\n",
    "where $\\epsilon = [\\epsilon_e^T, \\epsilon_h^T]^T$, $\\tilde{e} = e(q,t)- e_\\text{des}(t)$, and $\\tilde{h} = h(q,t)- h_\\text{lower}(t)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConstraintBasedController:\n",
    "    \"\"\"\n",
    "    A constraint-based feedback controller for robotic systems.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_joints, R, mu=1e-5):\n",
    "        \"\"\"\n",
    "        Initializes the constraint-based feedback controller.\n",
    "\n",
    "        Parameters:\n",
    "        num_joints (int): Number of robot joints.\n",
    "        R (numpy.ndarray): weight of each joint\n",
    "        mu (float, optional): Regularization coefficient. Default is 1e-5.\n",
    "        \"\"\"\n",
    "        self.nq = num_joints  # Number of robot joints\n",
    "        self.opti_QP = ca.Opti('conic')  # Create an optimization problem\n",
    "\n",
    "        # Define parameters for joint states and time\n",
    "        self.q = self.opti_QP.parameter(self.nq)\n",
    "        self.t = self.opti_QP.parameter()\n",
    "\n",
    "        # Define decision variables (joint velocities)\n",
    "        self.u = self.opti_QP.variable(self.nq)\n",
    "\n",
    "        # Define the objective function with regularization\n",
    "        self.objective = mu * self.u.T @ np.diag(R) @ self.u\n",
    "        self.initialized = False\n",
    "\n",
    "    def add_task(self, expr, target, gain_k, hard=False, weight=1):\n",
    "        \"\"\"\n",
    "        Adds a task to the controller.\n",
    "\n",
    "        Parameters:\n",
    "        expr (casadi.MX): Expression representing the task.\n",
    "        target (casadi.MX): Target value for the task.\n",
    "        gain_k (float): Gain for the task.\n",
    "        hard (bool, optional): If True, the task is a hard constraint. Default is False.\n",
    "        weight (float, optional): Weight of the task in the objective function. Default is 1.\n",
    "\n",
    "        Returns:\n",
    "        None\n",
    "        \"\"\"\n",
    "        # Compute the error and its derivative\n",
    "        e = expr - target\n",
    "        error_dot = ca.jtimes(e, self.q, self.u) + ca.jacobian(e, self.t)\n",
    "\n",
    "        if hard:\n",
    "            # Add a hard constraint\n",
    "            self.opti_QP.subject_to(error_dot == -gain_k * e)\n",
    "        else:\n",
    "            # Add a soft constraint to the objective function\n",
    "            eps = error_dot + gain_k * e\n",
    "            self.objective += weight * (eps.T @ eps)\n",
    "\n",
    "    def add_inequality(self, expr, gain_k, ub=None, lb=None, hard=False, weight=1):\n",
    "        \"\"\"\n",
    "        Adds an inequality constraint to the controller.\n",
    "\n",
    "        Parameters:\n",
    "        expr (casadi.MX): Expression representing the inequality constraint.\n",
    "        gain_k (float): Gain for the constraint.\n",
    "        ub (float, optional): Upper bound of the inequality constraint. Default is None.\n",
    "        lb (float, optional): Lower bound of the inequality constraint. Default is None.\n",
    "        hard (bool, optional): If True, the constraint is hard. Default is False.\n",
    "        weight (float, optional): Weight of the constraint in the optimization problem. Default is 1.\n",
    "\n",
    "        Returns:\n",
    "        None\n",
    "        \"\"\"\n",
    "        # Define slack variable for soft constraints\n",
    "        eps = 0 if hard else self.opti_QP.variable(expr.shape[0])\n",
    "        if not hard:\n",
    "            # Add the slack variable to the objective function\n",
    "            self.objective += weight * (eps.T @ eps)\n",
    "\n",
    "        if ub is not None:\n",
    "            # Compute the error and its derivative for the upper bound\n",
    "            e = expr - ub\n",
    "            error_dot = ca.jtimes(e, self.q, self.u) + ca.jacobian(e, self.t)\n",
    "            # jtimes is a more efficient way of computing: ca.jacobian(e, self.q)@self.u\n",
    "\n",
    "            # Add an upper bound constraint\n",
    "            self.opti_QP.subject_to(error_dot <= -gain_k * e + eps)\n",
    "\n",
    "        if lb is not None:\n",
    "            # Compute the error and its derivative for the lower bound\n",
    "            e = expr - lb\n",
    "            error_dot = ca.jtimes(e, self.q, self.u) + ca.jacobian(e, self.t)\n",
    "            # Add a lower bound constraint\n",
    "            self.opti_QP.subject_to(error_dot >= -gain_k * e + eps)\n",
    "\n",
    "    def initialize(self):\n",
    "        \"\"\"\n",
    "        Initializes the controller by setting up the optimization problem.\n",
    "\n",
    "        Returns:\n",
    "        None\n",
    "        \"\"\"\n",
    "        # Set the objective function of the QP problem\n",
    "        self.opti_QP.minimize(self.objective)\n",
    "\n",
    "        # Set solver options and initialize the solver\n",
    "        p_opts = {\"expand\": True, \"printLevel\": \"none\"}\n",
    "        s_opts = {}\n",
    "        self.opti_QP.solver('qpoases', p_opts, s_opts)\n",
    "\n",
    "        # Convert the optimization problem into a callable function\n",
    "        self.controller_func = self.opti_QP.to_function(\n",
    "            'solver', [self.q, self.t], [self.u], ['q', 't'], ['dq'])\n",
    "        self.initialized = True\n",
    "\n",
    "    def __call__(self, q, t):\n",
    "        \"\"\"\n",
    "        Executes the controller with the given state and time.\n",
    "\n",
    "        Parameters:\n",
    "        q (numpy.ndarray): State vector.\n",
    "        t (float): Current time.\n",
    "\n",
    "        Returns:\n",
    "        numpy.ndarray: Desired joint velocities if initialized, otherwise zeros.\n",
    "        \"\"\"\n",
    "        if self.initialized:\n",
    "            # Call the controller function with the current state and time\n",
    "            return self.controller_func(q, t).full().ravel()\n",
    "        else:\n",
    "            print(\"First initialize the controller before calling it.\")\n",
    "            return np.zeros(self.nq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.1 : Add collision avoidance\n",
    "\n",
    "- 3.1.1 Modify the task specification:\n",
    "    - The end-effector remains at least 0.2 m from the origin of the obstacle, \n",
    "    - While following the desired trajectory.\n",
    "- 3.1.2 What are some inherent limitations of the collision avoidance behavior? How would you improve it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "qpOASES -- An Implementation of the Online Active Set Strategy.\n",
      "Copyright (C) 2007-2015 by Hans Joachim Ferreau, Andreas Potschka,\n",
      "Christian Kirches et al. All rights reserved.\n",
      "\n",
      "qpOASES is distributed under the terms of the \n",
      "GNU Lesser General Public License 2.1 in the hope that it will be \n",
      "useful, but WITHOUT ANY WARRANTY; without even the implied warranty \n",
      "of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. \n",
      "See the GNU Lesser General Public License for more details.\n",
      "\n",
      "\n",
      "qpOASES -- An Implementation of the Online Active Set Strategy.\n",
      "Copyright (C) 2007-2015 by Hans Joachim Ferreau, Andreas Potschka,\n",
      "Christian Kirches et al. All rights reserved.\n",
      "\n",
      "qpOASES is distributed under the terms of the \n",
      "GNU Lesser General Public License 2.1 in the hope that it will be \n",
      "useful, but WITHOUT ANY WARRANTY; without even the implied warranty \n",
      "of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. \n",
      "See the GNU Lesser General Public License for more details.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "controller = ConstraintBasedController(num_joints=7, mu=1e-4, R=np.ones(7))\n",
    "\n",
    "q = controller.q\n",
    "t = controller.t\n",
    "\n",
    "# get the relevant transformations\n",
    "T_world_ee = T_world_ee_fn(q)\n",
    "T_world_goal = T_world_goal_fn(t)\n",
    "\n",
    "########################\n",
    "# track the trajectory #\n",
    "########################\n",
    "T_ee_goal = ta.inverse_SE3(T_world_ee) @ T_world_goal\n",
    "\n",
    "controller.add_task(\n",
    "    expr = T_ee_goal[:3, 3],\n",
    "    target = 0,\n",
    "    gain_k = 5,\n",
    "    weight = 1\n",
    ")\n",
    "\n",
    "R_ee_goal = T_ee_goal[:3, :3]\n",
    "controller.add_task(\n",
    "    expr=ta.axis_angle_from_rotation_matrix(R_ee_goal),\n",
    "    target=0,\n",
    "    gain_k=5,\n",
    "    weight=1\n",
    ")\n",
    "\n",
    "####################\n",
    "# add joint limits #\n",
    "####################\n",
    "\n",
    "controller.add_inequality(\n",
    "    expr = q,\n",
    "    ub=robot.model.upperPositionLimit[:7],\n",
    "    lb=robot.model.lowerPositionLimit[:7],\n",
    "    gain_k = 5,\n",
    "    hard = True\n",
    ")\n",
    "\n",
    "###########################\n",
    "# add collision avoidance #\n",
    "###########################\n",
    "\n",
    "T_world_obstacle = T_world_obstacle_fn(t)\n",
    "\n",
    "##################################\n",
    "# TODO: define constraints\n",
    "\n",
    "# Compute the distance between the end effector and the obstacle\n",
    "distance = ca.norm_2(T_world_obstacle[:3, 3] - T_world_ee[:3, 3])\n",
    "\n",
    "# Add a constraint to keep the distance between the end effector and the obstacle above a certain threshold\n",
    "controller.add_inequality(\n",
    "    expr=distance,\n",
    "    lb=0.2,\n",
    "    gain_k=5,\n",
    "    hard=True,\n",
    "    weight=1e4\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##################################\n",
    "\n",
    "\n",
    "#############################\n",
    "# initialize the controller #\n",
    "#############################\n",
    "controller.initialize()\n",
    "\n",
    "simulate(controller, q0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.2 : Remain fixed distance and perpendicular to the sphere\n",
    "\n",
    "- 3.2.1 Modify the task specification:\n",
    "    - Remain 0.15 m from the origin of the sphere (previously the obstacle)\n",
    "    - Keep the z-axis of the end effector (shown in blue) perpendicular to the sphere\n",
    "    - Change it to keep the x-axis or y-axis perpendicular to sphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "qpOASES -- An Implementation of the Online Active Set Strategy.\n",
      "Copyright (C) 2007-2015 by Hans Joachim Ferreau, Andreas Potschka,\n",
      "Christian Kirches et al. All rights reserved.\n",
      "\n",
      "qpOASES is distributed under the terms of the \n",
      "GNU Lesser General Public License 2.1 in the hope that it will be \n",
      "useful, but WITHOUT ANY WARRANTY; without even the implied warranty \n",
      "of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. \n",
      "See the GNU Lesser General Public License for more details.\n",
      "\n",
      "\n",
      "qpOASES -- An Implementation of the Online Active Set Strategy.\n",
      "Copyright (C) 2007-2015 by Hans Joachim Ferreau, Andreas Potschka,\n",
      "Christian Kirches et al. All rights reserved.\n",
      "\n",
      "qpOASES is distributed under the terms of the \n",
      "GNU Lesser General Public License 2.1 in the hope that it will be \n",
      "useful, but WITHOUT ANY WARRANTY; without even the implied warranty \n",
      "of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. \n",
      "See the GNU Lesser General Public License for more details.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "controller = ConstraintBasedController(num_joints=7, mu=1e-4, R=np.ones(7))\n",
    "\n",
    "q = controller.q\n",
    "t = controller.t\n",
    "\n",
    "# get the relevant transformations\n",
    "T_world_ee = T_world_ee_fn(q)\n",
    "T_world_obstacle = T_world_obstacle_fn(t)\n",
    "T_world_goal = T_world_goal_fn(t)\n",
    "\n",
    "####################\n",
    "# add joint limits #\n",
    "####################\n",
    "\n",
    "controller.add_inequality(\n",
    "    expr=q,\n",
    "    ub=robot.model.upperPositionLimit[:7],\n",
    "    lb=robot.model.lowerPositionLimit[:7],\n",
    "    gain_k=10,\n",
    "    hard=True\n",
    ")\n",
    "\n",
    "###########################################################\n",
    "# maintain desired position and perpendicular orientation #\n",
    "###########################################################\n",
    "\n",
    "##################################\n",
    "# TODO: define constraints\n",
    "\n",
    "T_ee_obstacle = ta.inverse_SE3(T_world_ee) @ T_world_obstacle\n",
    "dist = T_ee_obstacle[:3, 3]\n",
    "controller.add_task(\n",
    "    expr=dist,\n",
    "    target= np.array([0, 0, 0.15]),\n",
    "    gain_k=10,\n",
    "    weight=1e4\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##################################\n",
    "\n",
    "\n",
    "#############################\n",
    "# initialize the controller #\n",
    "#############################\n",
    "controller.initialize()\n",
    "\n",
    "simulate(controller, q0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.3 : (Optional) Explore the nullspace of the robot\n",
    "\n",
    "- 3.3.1 Provide the following task specification\n",
    "    - Keep the end-effector at a fixed pose (position and/or orientation)\n",
    "    - Wiggle some of the joints.    \n",
    "- 3.3.2 Add a constraint to fix one of the robot joints (turning it into a 6 DOF robot), and repeat the task.\n",
    "- 3.3.3 Rotate around a fixed position that is 0.1 m along the z-axis of the end-effector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller = ConstraintBasedController(num_joints=7, mu=1e-4, R=np.ones(7))\n",
    "\n",
    "q = controller.q\n",
    "t = controller.t\n",
    "\n",
    "# get the relevant transformations\n",
    "T_world_ee = T_world_ee_fn(q)\n",
    "\n",
    "\n",
    "####################\n",
    "# add joint limits #\n",
    "####################\n",
    "\n",
    "controller.add_inequality(\n",
    "    expr=q,\n",
    "    ub=robot.model.upperPositionLimit[:7],\n",
    "    lb=robot.model.lowerPositionLimit[:7],\n",
    "    gain_k=10,\n",
    "    hard=True\n",
    ")\n",
    "\n",
    "############################\n",
    "# stay at a fixed position #\n",
    "############################\n",
    "\n",
    "##################################\n",
    "# TODO: define constraints\n",
    "\n",
    "\n",
    "##################################\n",
    "\n",
    "\n",
    "#############################\n",
    "# initialize the controller #\n",
    "#############################\n",
    "controller.initialize()\n",
    "\n",
    "simulate(controller, q0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py13roboticscourse)",
   "language": "python",
   "name": "py13roboticscourse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
